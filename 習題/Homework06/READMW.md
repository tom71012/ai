### 說明(參考ChatGPT):

1.定義一個名為 `CrossEntropyLoss` 的類別，用於計算交叉熵損失。
在這個類別中，定義一個 `__call__` 方法，該方法接受模型的預測值 `y_pred` 和真實標籤 `y_true`，並返回交叉熵損失的值。
在計算損失值時，我們使用了一個小的 epsilon 值來避免數值不穩定性。

2.在測試部分，加載 MNIST 數據集並進行了一些預處理，包括將像素值正規化為 0 到 1 之間的範圍，並將圖像數據重塑為一維數組。並將標籤轉換為 one-hot 編碼形式。

3.初始化了模型的權重 `W`，並創建 `CrossEntropyLoss` 的一個實例 `loss_layer`。

#### 訓練:

使用隨機梯度下降算法來更新模型的權重。在每一步迭代中，從訓練集中隨機抽取一個批次數據，然後將其餵入模型中獲取預測值。接著使用 `CrossEntropyLoss` 層計算損失值，並使用自動微分計算損失對權重的梯度。最後，根據梯度更新模型的權重。

#### 測試:

測試部分，我們使用訓練好的模型對測試數據進行預測，並計算準確率。
